# Soapy - Hybrid SOAP/REST AI API System

Soapy is a hybrid SOAP/REST API system providing enterprise-grade conversation management with Git-backed storage. The system enables SOAP submission for legacy enterprise integration while offering modern REST retrieval with OpenAI/Anthropic-compatible formats.

## Features

- ‚úÖ **Hybrid SOAP/REST**: SOAP for enterprise clients, REST for modern clients
- ‚úÖ **Git-Backed Storage**: Every conversation is a Git repository with cryptographic audit trails
- ‚úÖ **Multi-Format Support**: OpenAI, Anthropic, and SOAP XML formats
- ‚úÖ **Streaming**: SSE and WebSocket support for real-time responses
- ‚úÖ **Conversation Branching**: Git branches enable alternative conversation paths
- ‚úÖ **Multi-Provider AI**: OpenAI, Anthropic, Ollama, LM Studio, and any OpenAI-compatible provider
- ‚úÖ **CLI Tools**: Git-style sub-command interface (soapy git, soapy convert, soapy ai)
- ‚úÖ **Optional Authentication**: API key-based authentication with organization access control

## Tech Stack

- **Backend**: Node.js 20+ with TypeScript 5.x (strict mode)
- **Module System**: ES modules throughout
- **REST**: Fastify v5.x
- **SOAP**: strong-soap v5.x
- **Git**: isomorphic-git v1.x
- **AI**: openai v4.x, @anthropic-ai/sdk v0.x
- **Testing**: Vitest v1.x
- **Frontend**: Vite + React + TypeScript

## Project Structure

```
.
‚îú‚îÄ‚îÄ backend/              # Backend API server
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lib/         # Core libraries (git-storage, format-converter, etc.)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/         # SOAP + REST endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cli/         # CLI tools
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models/      # Data models
‚îÇ   ‚îî‚îÄ‚îÄ tests/           # Contract, integration, and unit tests
‚îú‚îÄ‚îÄ frontend/            # Vite test client
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ components/  # UI components
‚îÇ       ‚îî‚îÄ‚îÄ services/    # API clients
‚îî‚îÄ‚îÄ specs/               # Feature specifications and contracts
```

## Quick Start

### Prerequisites

- Node.js 20+ (check: `node --version`)
- Git CLI (check: `git --version`)

### Installation

```bash
# Clone repository
git clone https://github.com/johnhenry/soapy.git
cd soapy

# Install backend dependencies
cd backend
npm install

# Copy environment file and configure
cp .env.example .env
# Edit .env to add your API keys and provider configurations
# Supports: OpenAI, Anthropic, Ollama, LM Studio, and custom OpenAI-compatible providers

# Build backend
npm run build

# Install frontend dependencies
cd ../frontend
npm install
```

### Running

```bash
# Terminal 1: Start backend server
cd backend
npm run dev
# Server will start on http://localhost:3000
# WSDL available at: http://localhost:3000/soap?wsdl
# API Documentation at: http://localhost:3000/docs

# Terminal 2: Start frontend test client
cd frontend
npm run dev
# Opens on http://localhost:5173
```

### AI Provider Configuration

Soapy supports multiple AI providers. Configure them in `backend/.env`:

#### OpenAI
```bash
OPENAI_API_KEY=sk-your-key-here
OPENAI_BASE_URL=https://api.openai.com/v1  # Optional: custom endpoint
```

#### Anthropic
```bash
ANTHROPIC_API_KEY=sk-ant-your-key-here
```

#### Ollama (Local LLM Server)
```bash
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_MODEL=llama2  # or llama3, mistral, codellama, etc.
```

Run Ollama: `ollama serve` then `ollama pull llama2`

#### LM Studio (Local LLM Server)
```bash
LMSTUDIO_BASE_URL=http://localhost:1234/v1
LMSTUDIO_MODEL=local-model  # Set to your loaded model name
```

Start LM Studio server from the UI, load a model, and use the local server option.

#### Custom OpenAI-Compatible Provider
```bash
OPENAI_COMPATIBLE_BASE_URL=https://your-provider.com/v1
OPENAI_COMPATIBLE_MODEL=your-model-name
OPENAI_COMPATIBLE_API_KEY=your-api-key  # If required
```

Any provider supporting OpenAI's chat completion API format will work (e.g., Together AI, Groq, LocalAI, etc.).

üìñ **[Full AI Provider Integration Guide](docs/AI_PROVIDERS.md)** - Detailed setup instructions, examples, and troubleshooting for all providers.

### Testing

```bash
# Run all tests
cd backend
npm test

# Run tests in watch mode
npm run test:watch

# Run tests with UI
npm run test:ui
```

**Testing with AI Providers:**

To run tests with actual AI provider integration, configure API keys in your environment:

```bash
# For GitHub Actions or CI/CD
# Add repository secrets: OPENAI_API_KEY and ANTHROPIC_API_KEY

# For local testing
# Create backend/.env file with:
export OPENAI_API_KEY=sk-your-key-here
export ANTHROPIC_API_KEY=sk-ant-your-key-here

# Then run tests
npm test
```

Note: Most tests use mock data and don't require API keys. Keys are only needed for live AI integration tests.

### CLI Tools

Soapy provides a unified CLI with git-style sub-commands:

```bash
# Main help
npm run soapy -- --help

# Git operations
npm run soapy -- git list-conversations
npm run soapy -- git create-conversation --id conv-123 --org org-456
npm run soapy -- git get-messages --id conv-123 --json

# Format conversion
echo '{"messages":[...]}' | npm run soapy -- convert to-openai
npm run soapy -- convert openai-to-anthropic < input.json > output.json

# AI operations (configure providers in .env)
npm run soapy -- ai generate --provider openai --prompt "Hello"
npm run soapy -- ai stream --provider anthropic --prompt "Tell me a story"
npm run soapy -- ai generate --provider ollama --prompt "What is AI?"
npm run soapy -- ai generate --provider lmstudio --prompt "Explain quantum computing"

# Health check
npm run health
```

### Optional Authentication

Authentication is disabled by default. To enable:

```bash
# In .env file:
AUTH_ENABLED=true
AUTH_REQUIRE_ORG=true
API_KEYS=key1:org-abc:user-1,key2:org-xyz:user-2
```

Then use API keys in requests:

```bash
# Using X-API-Key header
curl -H "X-API-Key: key1" http://localhost:3000/v1/chat/conv-123

# Using Authorization Bearer token
curl -H "Authorization: Bearer key1" http://localhost:3000/v1/chat/conv-123
```

## API Endpoints

### Documentation

- `GET /docs` - Interactive Swagger UI documentation
- `GET /docs/json` - OpenAPI 3.0 specification (JSON)

### SOAP Endpoints

- `GET /soap?wsdl` - Retrieve WSDL contract
- `POST /soap` - SOAP operations (16 total):
  - CommitMessage
  - BranchConversation
  - GetConversation
  - CommitToolCall
  - CommitToolResult
  - CommitFile
  - GetFile
  - GetCompletion
  - ListProviders
  - GetProviderModels
  - ListConversations
  - DeleteConversation
  - ListBranches
  - DeleteBranch
  - ListFiles

### REST Endpoints

Core conversation endpoints:
- `POST /v1/chat/:id/messages` - Submit message
- `GET /v1/chat/:id?format={openai|anthropic|soap}` - Get conversation
- `POST /v1/chat/:id/branch` - Create branch
- `DELETE /v1/chat/:id/branch/:branchName` - Delete branch
- `GET /v1/chat/:id/branches` - List branches
- `DELETE /v1/chat/:id` - Delete conversation
- `GET /v1/conversations` - List all conversations

Tool support:
- `POST /v1/chat/:id/tools/call` - Submit tool call
- `POST /v1/chat/:id/tools/result` - Submit tool result

File operations:
- `POST /v1/chat/:id/files` - Upload file
- `GET /v1/chat/:id/files` - List files
- `GET /v1/chat/:id/files/:filename` - Download file

Streaming:
- `GET /v1/chat/:id/completion/stream` - Stream completion (SSE)
- `POST /v1/chat/:id/messages/stream` - Stream messages (SSE)

AI Provider management:
- `GET /v1/providers` - List available AI providers
- `GET /v1/providers/:provider/models` - List models for provider
- `POST /v1/chat/:id/completion` - Direct completion endpoint

## Development Status

### Completed ‚úÖ

- [x] Backend project setup with TypeScript + ES modules
- [x] Data models (5 entities: Conversation, Message, Branch, ToolCall, ToolResult)
- [x] SOAP API with WSDL serving (16 operations implemented)
- [x] REST API with 17 endpoints (including file operations, streaming, and provider management)
- [x] Core libraries (git-storage, format-converter, ai-providers, auth)
- [x] Integration tests (6 scenarios, 48/58 tests passing - 82.8%)
- [x] CLI tools (4 tools: soapy-health, soapy-git, soapy-convert, soapy-ai)
- [x] Frontend test client (Vite + React)
- [x] Streaming support (SSE)
- [x] Authentication/authorization (optional, configurable via AUTH_ENABLED)
- [x] File attachment support (CommitFile, GetFile SOAP + REST endpoints)

### Future Enhancements üöÄ

- [ ] Production deployment configuration
- [x] Additional AI provider integrations (Ollama, LM Studio, OpenAI-compatible providers)
- [ ] Enhanced file storage with actual Git persistence
- [ ] Performance optimization for large conversations

## Testing

Current test results:
- ‚úÖ Contract tests: 33/33 tests passing (SOAP WSDL, REST API)
- ‚ö†Ô∏è Integration tests: 48/58 tests passing (6 scenarios complete, 10 tests failing)
- **Total: 48/58 tests passing (82.8%)**

### Known Test Issues
- Branching scenario: 1 test failing (branch creation endpoint)
- Error handling scenario: 2 tests failing (SOAP fault handling, streaming errors)
- Additional failures: 7 tests need investigation

See [INCONSISTENCY_REPORT.md](INCONSISTENCY_REPORT.md) for details on test failures.

## Constitutional Principles

This project follows 7 constitutional principles:

1. **Library-First**: All logic in standalone libraries
2. **CLI Interface**: Every library has a CLI tool
3. **TDD**: Tests written first, must fail initially
4. **Integration Tests**: 6 acceptance scenarios
5. **Observability**: JSON logging, Git audit trails
6. **Versioning**: WSDL/OpenAPI versioned independently
7. **Simplicity**: Use standard libraries, defer optimization

## Contributing

This project was built following the [GitHub SpecKit](https://github.com/github/spec-kit) specification workflow.

## License

MIT
